{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Installing All Dependencies</b></h1>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FUdSZJCl3PSR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ViDfiqhfBXkw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0ee4c88-d7a3-4426-b4ee-6d36f04f4823"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m617.9/617.9 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.5/409.5 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.6/442.6 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q PyPDF2 langchain google-generativeai langchain-google-genai pypdf langchain-community chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Importing All Libraries</b></h1>"
      ],
      "metadata": {
        "id": "bwF8kB363ifR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.vectorstores import Chroma\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L-cXcZJ_BjdC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>API Key Fetching</b></h1>"
      ],
      "metadata": {
        "id": "aLstiD0d3oVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['GOOGLE_API_KEY'] = 'AIzaSyBzEiw3MNo8q3EBzfXL2oCPUwLNbg1nEww'"
      ],
      "metadata": {
        "id": "lp-QkaabpBtQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Enabled Google Generative AI</b></h1>\n",
        "\n",
        "1. **Prepared the test_sample_1.pdf file**\n",
        "\n",
        "2. **Execute the Document Retrieval Code**\n",
        "\n",
        "3. **Result Handling**"
      ],
      "metadata": {
        "id": "S-48s-Tf4gdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai  import ChatGoogleGenerativeAI\n",
        "from langchain_google_genai  import GoogleGenerativeAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "class DocumentRetrievalQA:\n",
        "    def __init__(self, pdf_path):\n",
        "        self.pdf_path = pdf_path\n",
        "\n",
        "        # Initialize models\n",
        "        self.llm = ChatGoogleGenerativeAI(model=\"gemini-pro\")\n",
        "        self.embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
        "\n",
        "    def load_and_process_pdf(self):\n",
        "        loader = PyPDFLoader(self.pdf_path)\n",
        "        text_splitter = CharacterTextSplitter(\n",
        "            separator=\".\",\n",
        "            chunk_size=300,\n",
        "            chunk_overlap=100,\n",
        "            length_function=len,\n",
        "            is_separator_regex=False,\n",
        "        )\n",
        "        pages = loader.load_and_split(text_splitter)\n",
        "\n",
        "        # Create vector database\n",
        "        self.vectordb = Chroma.from_documents(pages, self.embeddings)\n",
        "\n",
        "    def create_retrieval_chain(self):\n",
        "        # Configure Chroma as a retriever with top_k=5\n",
        "        retriever = self.vectordb.as_retriever(search_kwargs={\"k\": 5})\n",
        "\n",
        "        # Create the retrieval chain\n",
        "        template = \"\"\"\n",
        "        You are a helpful AI assistant.\n",
        "        Answer based on the context provided.\n",
        "        context: {context}\n",
        "        input: {input}\n",
        "        answer:\n",
        "        \"\"\"\n",
        "        prompt = PromptTemplate.from_template(template)\n",
        "        combine_docs_chain = create_stuff_documents_chain(self.llm, prompt)\n",
        "        self.retrieval_chain = create_retrieval_chain(retriever, combine_docs_chain)\n",
        "\n",
        "    def query(self, query):\n",
        "        response = self.retrieval_chain.invoke({\"input\": query})\n",
        "        return response[\"answer\"]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    document_qa = DocumentRetrievalQA(\"/content/test_sample_1.pdf\")\n",
        "    document_qa.load_and_process_pdf()\n",
        "    document_qa.create_retrieval_chain()\n",
        "\n",
        "    query = \"How does ChatGPT's style differ from that of French presidents?\"\n",
        "    answer = document_qa.query(query)\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "0gaXR_pKtIdh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ce62c4d-3042-4f5f-a220-5000a06bb667"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 36 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 101 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 103 0 (offset 0)\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 322, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 320, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 376, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 303, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 305, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 360, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 314, which is longer than the specified 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatGPT's style differs from that of French presidents in the following ways:\n",
            "\n",
            "- POS distribution: The POS distribution in ChatGPT-generated texts differs from that in speeches written by French presidents.\n",
            "- Vocabulary: The vocabulary used by ChatGPT differs from that used by French presidents.\n",
            "- Most frequent words: The most frequent words used by ChatGPT differ from those used by French presidents.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Prepared the test_sample_2.pdf file**\n",
        "\n",
        "2. **Execute the Document Retrieval Code**\n",
        "\n",
        "3. **Result Handling**"
      ],
      "metadata": {
        "id": "Tw5QCSUT5e6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    document_qa = DocumentRetrievalQA(\"/content/test_sample_2.pdf\")\n",
        "    document_qa.load_and_process_pdf()\n",
        "    document_qa.create_retrieval_chain()\n",
        "\n",
        "    query = \"How do the stylistic and rhetorical features of GPT-generated State of the Union addresses compare to those written by U.S. presidents in terms of sentence structure, vocabulary, and tone?\"\n",
        "    answer = document_qa.query(query)\n",
        "    print(answer)"
      ],
      "metadata": {
        "id": "nnSpiaP1oT1T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bf7022b-0953-4e18-d6c7-abcc3718df59"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 22 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 24 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 26 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 28 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 46 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 53 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 55 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 69 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 71 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 78 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 80 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 82 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 84 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 90 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 104 0 (offset 0)\n",
            "WARNING:pypdf._reader:Ignoring wrong pointing object 106 0 (offset 0)\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 570, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 330, which is longer than the specified 300\n",
            "WARNING:langchain_text_splitters.base:Created a chunk of size 608, which is longer than the specified 300\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-generated State of the Union addresses differ from those written by U.S. presidents in terms of sentence structure, vocabulary, and tone. GPT-generated speeches tend to have simpler sentence structures, use less complex vocabulary, and have a more neutral tone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LWRg_nuO2B4C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}